{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac13e8a-a25e-4be3-8aec-8b569a31f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from urllib.parse import urljoin\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a57428-b233-4dba-b75e-6ff25cf84a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b616f072ca842f5b07ae41c3aec4904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML Projects\\Blog-Bot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\prxsh\\.cache\\huggingface\\hub\\models--google--pegasus-xsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56642374a46547fba108865e8392ec73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3429411bd0d240629e34cdb81277fb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55faf32fb0f147ec86d854d8af6b9713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c86f1a09794fe9bd6bca07bb9cefee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dba04a0df4410bb1d6ba3f2ba92c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8933775a16894d0d817e564ea6bee92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pegasus load\n",
    "model_name='google/pegasus-xsum'\n",
    "tokenizer= PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34380fdd-243f-4695-a307-7602f738bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url='https://www.wired.com'\n",
    "relative_url='/tag/machine-learning/\n",
    "page= requests.get(base_url)\n",
    "soup=BeautifulSoup(page.text, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5ed4b5-7241-4644-aec6-e3b23dced49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relative_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text\u001b[38;5;241m.\u001b[39msplit()[:\u001b[38;5;241m1024\u001b[39m])\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m---> 22\u001b[0m content\u001b[38;5;241m=\u001b[39m get_content_from_url(base_url, \u001b[43mrelative_url\u001b[49m)\n\u001b[0;32m     23\u001b[0m content \u001b[38;5;241m=\u001b[39m preprocess_text(content)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# ParaPHRASER FUNCTION\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'relative_url' is not defined"
     ]
    }
   ],
   "source": [
    "def get_content_from_url(base_url, relative_url):\n",
    "    try:\n",
    "        absolute_url = urljoin(base_url, relative_url)\n",
    "        session = HTMLSession()\n",
    "        response = session.get(absolute_url)\n",
    "        response.raise_for_status() \n",
    "        content_element = response.html.find('div.body__inner-container', first=True)\n",
    "        if content_element:\n",
    "            content = content_element.text\n",
    "            return content\n",
    "        else:\n",
    "            print(f\"Content element not found in URL '{absolute_url}'\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching content from URL '{absolute_url}': {e}\")\n",
    "        return None\n",
    "        \n",
    "def preprocess_text(text):\n",
    "    if len(text.split()) > 1024:\n",
    "        text = ' '.join(text.split()[:1024])\n",
    "    return text\n",
    "content= get_content_from_url(base_url, relative_url)\n",
    "content = preprocess_text(content)\n",
    "    \n",
    "# ParaPHRASER FUNCTION\n",
    "def paraphraser(text):\n",
    "    # Check the length of the input text\n",
    "    if len(text) > 1024:\n",
    "        print(\"Input text is too long for tokenization. Please ensure it is within 1024 tokens.\")\n",
    "        return None\n",
    "    inputs = tokenizer(text, max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=150, early_stopping=True)\n",
    "    paraphrased_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return paraphrased_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b319848-1ea8-45a6-bd85-28b7bb6ac2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_content = paraphraser(content)\n",
    "def extract_titles_and_content(base_url):\n",
    "    title_content_dict = {}\n",
    "    titles = soup.select('.SummaryItemHedBase-hiFYpQ')\n",
    "    for title in titles:\n",
    "        title_text = title.text.strip()\n",
    "        content_url = title.find_parent('a')['href']\n",
    "        \n",
    "        content = get_content_from_url(base_url, content_url)\n",
    "        if content is not None:\n",
    "            paraphrased_content= paraphraser(content)\n",
    "            title_content_dict[title_text] = paraphrased_content\n",
    "    return title_content_dict\n",
    "    \n",
    "title_content_dict = extract_titles_and_content(base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201195c7-ba6f-4019-b2f1-7c9f66c1e6a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title_content_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Titles with their indexes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (title, content) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtitle_content_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems(), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# print(f\"Content: {content}\\n\")\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'title_content_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#Titles with their indexes\n",
    "for i, (title, content) in enumerate(title_content_dict.items(), start=1):\n",
    "    print(f\"{i-1} : {title}\")\n",
    "    # print(f\"Content: {content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3012a97-5061-45b2-8555-691fb7cf3bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: This New Breed of AI Assistant Wants to Do Your Boring Office Chores\n",
      "Content: This week, OpenAI announced a service that makes it possible for just about anyone to build a custom version of ChatGPT, no coding skills required. The company suggests that users may want to build a bot that knows the rules of all board games, teaches kids about math, or can offer culinary advice. These GPTs, as OpenAI calls them, can also perform simple actions by connecting with internet services, for example searching through emails or ordering products from an online store.\n",
      "You can’t fault OpenAI for trying to build on the success of its smash hit ChatGPT. But maybe more chatbots is not what we need?\n",
      "Adept AI, a startup in San Francisco founded by veterans of OpenAI, Google, and DeepMind, is today launching an experimental AI agent that automates common chores in a more sophisticated and potentially powerful way than chatbots like ChatGPT. Instead of being limited to using online services that provide APIs to make them accessible to software, ACT-2 attempts to use a computer more like a human—by making sense of the pixels on a display and then taking action to control a browser and online services.\n",
      "Sign Up Today\n",
      "This is an edition of WIRED's Fast Forward newsletter, a weekly dispatch from the future by Will Knight, exploring AI advances and other technology set to change our lives.\n",
      "Adept’s demos show how ACT-2 can be used to do things like gathering info from emails and documents to fill out insurance claims, inputting information from emailed invoices into accounts-payable software, and coming up with a walking tour for a city by interacting with Google Maps.\n",
      "The way ACT-2 attempts to use the same user interfaces that humans do promises to make it a lot more capable and expansive. In theory that approach could allow a chatbot to do literally anything a person might do on their phone or computer. But operating that way is also more challenging for algorithms, and for now makes the agent more error prone.\n",
      "Under the hood, ACT-2 uses a large language model called Fuyu. It is similar to the one that powers many chatbots, but like ChatGPT it can handle both text and images (making it a “multimodal model”). The model analyzes what it sees on a computer screen and tries to translate the request a user typed into useful actions the bot should take. Adept uses reinforcement learning—a technique used to teach computers tasks including playing board games and video games—to instruct its AI on how to perform different tasks. This involves watching lots of humans perform specific tasks and trying to achieve similar performance for itself.\n",
      "David Luan, founder and CEO of Adept and previously VP of engineering at OpenAI, says that while chatbots have wowed everyone with their capabilities, it has proven challenging to get AI agents to work reliably. But he believes Adept and others are getting a lot closer to solving that.\n",
      "“This year they just weren’t there,” Luan says of today’s agents, including his own. “I think what's going to happen is next year there's going to be a giant war around agents that actually work.” Adept is initially designing its agents to perform only a limited number of simple but common office tasks, and it says they are now at least 95 percent reliable, which is sufficient for them to be commercially deployed at a few companies.\n",
      "Reaching that level of reliability just for the initial, limited tasks ACT-2 is designed for is a major breakthrough. For years, tools have existed to automate office tasks—what’s known as robotic process automation—but these are finicky to build and prone to breaking. If Adept and others can use AI to reliably automate a lot more tasks, it could transform office work and increase productivity.\n",
      "If Luan is right, then the battle to automate your most tedious chores could make the chatbot wars of 2023 seem relatively tame.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles_list = list(title_content_dict.items())\n",
    "third_title_index = 23\n",
    "if len(titles_list) > third_title_index:\n",
    "    third_title, third_content = titles_list[third_title_index]\n",
    "    print(f\"Title: {third_title}\")\n",
    "    print(f\"Content: {third_content[:5000]}\\n\")\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f07d0c-546e-47cc-85d0-9d90a6e856c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phrases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m phrase \u001b[38;5;129;01min\u001b[39;00m \u001b[43mphrases\u001b[49m:\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput_phrase: \u001b[39m\u001b[38;5;124m\"\u001b[39m, phrase)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'phrases' is not defined"
     ]
    }
   ],
   "source": [
    "for phrase in phrases:\n",
    "  print(\"-\"*100)\n",
    "  print(\"Input_phrase: \", phrase)\n",
    "  print(\"-\"*100)\n",
    "  para_phrases = parrot.augment(input_phrase=phrase)\n",
    "  for para_phrase in para_phrases:\n",
    "   print(para_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd1fdb-e4f5-4484-bcc9-ff3300df2840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
