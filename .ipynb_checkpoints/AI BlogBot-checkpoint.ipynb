{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cac13e8a-a25e-4be3-8aec-8b569a31f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from urllib.parse import urljoin\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03a57428-b233-4dba-b75e-6ff25cf84a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#pegasus load\n",
    "model_name='google/pegasus-xsum'\n",
    "tokenizer= PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34380fdd-243f-4695-a307-7602f738bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url='https://techcrunch.com'\n",
    "relative_url='/category/artificial-intelligence'\n",
    "url=urljoin(base_url, relative_url)\n",
    "page= requests.get(url)\n",
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c5ed4b5-7241-4644-aec6-e3b23dced49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_headlines(base_url, relative_url):\n",
    "    try:\n",
    "        absolute_url = urljoin(base_url, relative_url)\n",
    "        session = HTMLSession()\n",
    "        response = session.get(absolute_url)\n",
    "        response.raise_for_status() \n",
    "        # Find all elements containing both headline text and article URLs\n",
    "        headlines_elements = response.html.find('h2.post-block__title a')\n",
    "        # Extract headline text and article URLs as tuples\n",
    "        headlines = [(headline.text, headline.absolute_links.pop()) for headline in headlines_elements]\n",
    "        return headlines\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching headlines from URL '{absolute_url}': {e}\")\n",
    "        return None\n",
    "\n",
    "def get_article_content(article_url):\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(article_url)\n",
    "        response.raise_for_status()\n",
    "        content_element = response.html.find('div.article-content', first=True)\n",
    "        if content_element:\n",
    "            content = content_element.text\n",
    "            return content\n",
    "        else:\n",
    "            print(f\"Content element not found in URL '{article_url}'\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching content from URL '{article_url}': {e}\")\n",
    "        return None\n",
    "\n",
    "def get_paraphrased_content(original_content):\n",
    "    try:\n",
    "        print(\"Original Content Length:\", len(original_content))\n",
    "        # Split the original content into paragraphs\n",
    "        paragraphs = original_content.split('\\n\\n')  # Assuming paragraphs are separated by double line breaks\n",
    "        paraphrased_paragraphs = []\n",
    "        \n",
    "        # Paraphrase each paragraph\n",
    "        for paragraph in paragraphs:\n",
    "            # Split each paragraph into chunks of 512 tokens\n",
    "            chunks = [paragraph[i:i+512] for i in range(0, len(paragraph), 512)]\n",
    "            paraphrased_chunks = []\n",
    "            \n",
    "            # Paraphrase each chunk\n",
    "            for chunk in chunks:\n",
    "                inputs = tokenizer([chunk], return_tensors='pt', max_length=512, truncation=True)\n",
    "                summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=512, temperature=0.7, do_sample=True, early_stopping=True)\n",
    "                paraphrased_chunk = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "                paraphrased_chunks.append(paraphrased_chunk)\n",
    "                \n",
    "            # Combine the paraphrased chunks into a single string representing the paraphrased paragraph\n",
    "            paraphrased_paragraph = ' '.join(paraphrased_chunks)\n",
    "            paraphrased_paragraphs.append(paraphrased_paragraph)\n",
    "        \n",
    "        # Combine the paraphrased paragraphs into a single string representing the paraphrased content\n",
    "        paraphrased_content = '\\n\\n'.join(paraphrased_paragraphs)\n",
    "        \n",
    "        # Check if the paraphrased content is not empty\n",
    "        if paraphrased_content.strip():\n",
    "            return paraphrased_content\n",
    "        else:\n",
    "            print(\"Paraphrased content is empty\")\n",
    "            return original_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching or paraphrasing content: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd3bd568-01aa-4254-9953-634f7b93f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. ‘Embarrassing and wrong’: Google admits it lost control of image-generating AI\n",
      "1. Treating a chatbot nicely might boost its performance — here’s why\n",
      "2. Humane pushes Ai Pin ship date to mid-April\n",
      "3. Arc browser’s new AI-powered ‘pinch-to-summarize’ feature is clever, but often misses the mark\n",
      "4. Mutale Nkonde’s nonprofit is working to make AI less biased\n",
      "5. Armenia’s 10web brings AI website-building to WordPress\n",
      "6. Reddit says it’s made $203M so far licensing its data\n",
      "7. Stable Diffusion 3 arrives to solidify early lead in AI imagery against Sora and Gemini\n",
      "8. Chrome gets a built-in AI writing tool powered by Gemini\n",
      "9. Women in AI: Krystal Kauffman, research fellow at the Distributed AI Research Institute\n",
      "10. The women in AI making a difference\n",
      "11. DatologyAI is building tech to automatically curate AI training datasets\n",
      "12. Google pauses AI tool Gemini’s ability to generate images of people after historical inaccuracies\n",
      "13. Antler’s founder on its vertical AI bet in Southeast Asia\n",
      "14. Samsung is bringing Galaxy AI features to more devices\n",
      "15. Are you Blacker than ChatGPT? Take this quiz to find out\n",
      "16. Hundreds of AI luminaries sign letter calling for anti-deepfake legislation\n",
      "17. Match Group inks deal with OpenAI, says press release written by ChatGPT\n",
      "18. Google DeepMind forms a new org focused on AI safety\n",
      "19. China’s Moonshot AI zooms to $2.5B valuation, raising $1B for an LLM focused on long context\n"
     ]
    }
   ],
   "source": [
    "#Titles with their indexes\n",
    "headlines=get_headlines(base_url, relative_url)\n",
    "if headlines:\n",
    "    for i, (headline,_) in enumerate(headlines, 0):\n",
    "        print(f\"{i}. {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "949e9daa-f600-4ed1-bc51-6b36d3f56e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Title: Antler’s founder on its vertical AI bet in Southeast Asia\n",
      "\n",
      " Content: A growing roster of vertical AI startups is emerging in Southeast Asia to serve sectors ranging from seafood to finance. Singapore-based venture capital firm Antler recently made a bet on 37 of them, investing $5.1 million in total for pre-seed deals. Antler also announced a partnership with Khazanah, Malaysia’s sovereign wealth fund.\n",
      "“If you look at the rest of the world, there’s lots of horizontal AI and it’s becoming insanely competitive,” Antler co-founder and managing partner Jussi Salovaara tells TechCrunch. “What founders are increasingly looking to solve in this part of the world are practical problems in different industries.”\n",
      "He adds that even though Southeast Asia doesn’t have the talent pool to build something like OpenAI yet, they can take a customer-first approach to AI apps, solving pain points unique to different sectors and markets.\n",
      "Within verticalized AI, different trends are emerging in each country. For example, Vietnam has a large pool of technical talent. Founders there who are working on a consumer startup usually focus more on the domestic market at first, but B2B startups are more globally oriented from the beginning, Salovaara says. On the other hand, Indonesian startups tend not to target international expansion because their domestic market is so large, but Antler hopes to see more of them expand internationally.\n",
      "One of Antler’s investments is BorderDollar, which is building an invoice financing platform for cross-border logistics. Since funding structures are different in Southeast Asia than the rest of the world, BorderDollar used their own training data to build a credit scoring system.\n",
      "“You can’t really take something from the West and then just plug it in here and use that,” says Salovaara.\n",
      "Another member of Antler’s portfolio is CapGo, which Antler backed in large part because of the founders’ backgrounds: CapGo CTO Chen Yu worked on machine learning at Grab and CEO Yichen Guo earned a Harvard MBA and worked at Citi, Almanac and VIPKid as a product manager. CapGo automates data acquisition for market research, a pain point Salovaara is familiar with because he used to work at an investment bank.\n",
      "“It’s super unclear why you would throw endless amounts of human hours into researching a market when AI can do so much more effectively and efficiently,” he says, adding that CapGo’s competitive moat is its ability to build data sources that are tailored first for Southeast Asia. It plans to expand into the rest of the Asia-Pacific region.\n",
      "Both Zolo and Seafoody were created to solve problems in Southeast Asia’s food supply chain infrastructure. Based in Malaysia, Seafoody was founded by Eleen Kee, Samantha Ooi and Zach Leong. Kee, its CEO, comes from a family that has worked in the seafood industry for several generations. Seafoody is focused on using AI to eliminate middlemen in the seafood supply chain and sell directly to businesses. Zolo, meanwhile, is also simplifying the food supply chain by using AI to shorten the order management process, which usually entails a lot of back-and-forth between suppliers and restaurants on WhatsApp.\n",
      "Another startup Salovaara highlights is Malaysia-based Coex. It uses AI to digitize project claims and bills of quantity, so approvals, communication and preparing materials can all be performed more quickly. “Construction is obviously one of the most analog and old school industries, so this is largely a play to optimize capital efficiency and operational efficiency,” says Salovaara.\n",
      "Building a vertical AI startup comes with its own challenges. For example, the right team has to be put together and include not only a technical founder with the right expertise, but also someone who understands the industry they are targeting very well. They also need the right data for training. But once a vertical AI startup comes together, Salovaara says they can build a very deep competitive moat.\n",
      "“If you want to raise funding for a quote unquote ‘hardcore’ horizontal AI out of Southeast Asia, it would be challenging, especially to enter into a race with a company based in Silicon Valley,” he adds. “Trying to compete with a place that has more talent or a better funding infrastructure in this space, especially at the later stage, is still quite difficult. So these vertical plays are the way to go.”...\n",
      "Original Content Length: 4324\n",
      "\n",
      "Paraphrased Content:\n",
      "Horizontal AI is taking off in Asia, and it’s not just for big tech companies like Google and Facebook.... and it’s not just for big tech companies like Google and Facebook. “Southeast Asia has a lot to offer in terms of talent,” says OpenAI’s co-founder and chief technology officer, Peter Lee. Antler Ventures, a Jakarta-based venture capital firm, is looking to invest in B2B technology companies in Indonesia that are targeting international expansion. Antler Ventures, a Hong Kong-based venture capital firm, is backing BorderDollar, a Chinese-founded credit-scoring platform, which aims to make it easier for small businesses to get credit. CapGo, a Singapore-based artificial intelligence (AI) firm, has raised $5m (£3.4m) in funding from existing investors, including Sequoia Capital and Khosla Ventures. Two artificial intelligence (AI) start-ups have raised a total of $8m (£6m) in funding from venture capitalists and angel investors. In our series of letters from African journalists, film-maker and columnist Ahmed Salovaara looks at some of the African AI companies that are making a difference. In our series of letters from Asian journalists, editor-in-chief of The Straits Times, Mustapha Salovaara, looks at the challenges of setting up a vertical AI company in Southeast Asia. In our series of letters from African journalists, film-maker and columnist Mirtn  Mirtn looks at some of the key stories from the continent this year.\n"
     ]
    }
   ],
   "source": [
    "index=13\n",
    "if index>=0 and index<len(headlines):\n",
    "    _, article_url=headlines[index]\n",
    "    content=original_content(article_url)\n",
    "    if content:\n",
    "        print(f\"\\n Title: {headlines[index][0]}\")\n",
    "        print(f\"\\n Content: {content[:]}...\")\n",
    "        # Paraphrase the entire content\n",
    "        paraphrased_content=get_paraphrased_content(content)\n",
    "        if paraphrased_content:\n",
    "            print(\"\\nParaphrased Content:\")\n",
    "            print(paraphrased_content)\n",
    "        else:\n",
    "            print(\"Paraphrased content not available\")\n",
    "    else:\n",
    "        print(\"Content not available\")\n",
    "else:\n",
    "    print(\"Invalid index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7144e-4ab2-4122-88fc-dc1a789a5241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
